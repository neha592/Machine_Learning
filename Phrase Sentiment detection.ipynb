{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"attachment_train.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() ##this tells we dont have any missing values Task 1 done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 : making table of the category : defining the x and y\n",
    " STEP 1: first remove all unwanted words<br>\n",
    " Step 2: Vectorize the dataset according to the TF_IDF : call the instance of Tfidfvectorizr and set the parameter to vectorise <br>\n",
    " Step 3: fit the dataset with tfidf vectorizer <br>\n",
    " Step 4: Seperate the dependent variable that is Y our target variable<br>\n",
    " Step 5: now define the X variable by transforming it in tfidf vectorizer format.<br>\n",
    " Step 6: split the text/phrase inside the x into individual words<br>\n",
    " \n",
    " **NOTE : FIT means setting the rules for dataframe and transform means changing the datframe according to the set rule.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setword = set(stopwords.words('english'))  #step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectoriz_data = TfidfVectorizer(use_idf = True,lowercase= True, stop_words=setword,strip_accents='ascii') #Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words={\"couldn't\", 'or', 'to', 'that', 'my', 're', 'below', 'same', 'too', 'again', 'other', 'out', \"mustn't\", 'ourselves', \"she's\", 'during', \"shouldn't\", 'being', \"hasn't\", 'about', 'more', \"that'll\", 'shan', 'over', 'above', 's', 'her', 'hers', 'ain', 'he', 'his', 'them', 'in', 'won', 'by', ...nor', 'just', 'our', 'she', 'who', 'hadn', 'me', 'mustn', 'haven', 'your', 'against', 'had', 'been'},\n",
       "        strip_accents='ascii', sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectoriz_data.fit(df) #Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "\n",
    "### IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "## tf-idf score=TF(t)*IDF(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df[\"Sentiment\"]\n",
    "x = df[\"Phrase\"]       # Step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n",
      "(156060,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**only phrase and sentiment type is important in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = vectoriz_data.fit_transform(x)    #Step : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 15115)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<156060x15115 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 623022 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'series',\n",
       " 'of',\n",
       " 'escapades',\n",
       " 'demonstrating',\n",
       " 'the',\n",
       " 'adage',\n",
       " 'that',\n",
       " 'what',\n",
       " 'is',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'goose']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_1st_phrase = df[\"Phrase\"][1].split()\n",
    "split_1st_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(max(split_1st_phrase))\n",
    "print(len(split_1st_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15115 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** It means in the first phrase there are 14(len(split_1st_phrase)) words & out of which only 6 elements have been taken which are giving meaning and removing useless words which is removed by \"stopwords\", that;s why we'll get only 6 tf-idf values for the first the phrase.Likewise elements or words of all other phrases are taken into consideration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15115 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[156059]   # for last phrase there is only one elemnt stored to judge the value of word in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\n",
      "A series of escapades demonstrating the adage that what is good for the goose\n",
      "A series\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Phrase\"][0])\n",
    "print(df[\"Phrase\"][1])\n",
    "print(df[\"Phrase\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11756)\t0.21406381187\n",
      "  (0, 4545)\t0.338395250784\n",
      "  (0, 3466)\t0.301908610865\n",
      "  (0, 286)\t0.305101582652\n",
      "  (0, 5785)\t0.318946757333\n",
      "  (0, 5801)\t0.278014250714\n",
      "  (0, 523)\t0.196130467085\n",
      "  (0, 5559)\t0.322914576695\n",
      "  (0, 9138)\t0.234490943134\n",
      "  (0, 595)\t0.320026182374\n",
      "  (0, 9022)\t0.230649706998\n",
      "  (0, 586)\t0.268114018887\n",
      "  (0, 8747)\t0.164482161821\n",
      "  (0, 12772)\t0.155332083718\n",
      "  (1, 11756)\t0.320071242718\n",
      "  (1, 4545)\t0.505973370755\n",
      "  (1, 3466)\t0.451418030086\n",
      "  (1, 286)\t0.456192206715\n",
      "  (1, 5785)\t0.238446853975\n",
      "  (1, 5801)\t0.415690844436\n",
      "  (2, 11756)\t1.0\n",
      "  (4, 11756)\t1.0\n",
      "  (5, 4545)\t0.534068877641\n",
      "  (5, 3466)\t0.476484207687\n",
      "  (5, 286)\t0.481523483075\n",
      "  :\t:\n",
      "  (156049, 11385)\t0.539505216234\n",
      "  (156049, 9127)\t0.552565277797\n",
      "  (156049, 12999)\t0.635299720942\n",
      "  (156050, 11385)\t0.698600543069\n",
      "  (156050, 9127)\t0.715511901525\n",
      "  (156051, 11385)\t0.698600543069\n",
      "  (156051, 9127)\t0.715511901525\n",
      "  (156052, 11385)\t1.0\n",
      "  (156053, 1294)\t0.400689647833\n",
      "  (156053, 5294)\t0.385382441783\n",
      "  (156053, 6204)\t0.455400978279\n",
      "  (156053, 1014)\t0.491700177276\n",
      "  (156053, 2289)\t0.491700177276\n",
      "  (156054, 5294)\t0.420624993525\n",
      "  (156054, 6204)\t0.49704660299\n",
      "  (156054, 1014)\t0.536665300387\n",
      "  (156054, 2289)\t0.536665300387\n",
      "  (156055, 6204)\t1.0\n",
      "  (156056, 5294)\t0.484745227452\n",
      "  (156056, 1014)\t0.618474762809\n",
      "  (156056, 2289)\t0.618474762809\n",
      "  (156057, 1014)\t0.707106781187\n",
      "  (156057, 2289)\t0.707106781187\n",
      "  (156058, 1014)\t1.0\n",
      "  (156059, 2289)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(x) # here 0 is 1st phrase 11756 is the word, 0.21 is tf_idf value which tell the word holds 21.40% importance in 1st phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'series'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectoriz_data.get_feature_names()[11756]  # word at 11756 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(vectoriz_data.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a sample of output for vocabulury method is shown below ** <br>\n",
    "\n",
    "{'series': 11756, 'escapades': 4545, 'demonstrating': 3466, 'adage': 286, 'good': 5785, 'goose': 5801, 'also': 523, 'gander': 5559, 'occasionally': 9138,..........}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: predict the sentiment using Multinomial Na√Øve Bayes algorithm\n",
    "\n",
    "Step 1: train and test the data <br>\n",
    "Step 2: instantiate the naive bayes algorithm class MultinomialNB <br>\n",
    "Step 3: fit the model and predict <br>\n",
    "Step 4: now predict the probabilty of a phrase to be in any of the given category by predict proba<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95722     2\n",
       "147312    4\n",
       "36991     2\n",
       "150211    2\n",
       "140655    1\n",
       "154731    1\n",
       "124991    1\n",
       "140469    3\n",
       "94770     4\n",
       "12599     1\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39015,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   81   747   880    32     0]\n",
      " [   40  1832  4755   226     1]\n",
      " [    8   829 17530  1253    15]\n",
      " [    0   119  4912  3297    56]\n",
      " [    0    10   833  1430   129]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.05      0.09      1740\n",
      "          1       0.52      0.27      0.35      6854\n",
      "          2       0.61      0.89      0.72     19635\n",
      "          3       0.53      0.39      0.45      8384\n",
      "          4       0.64      0.05      0.10      2402\n",
      "\n",
      "avg / total       0.58      0.59      0.53     39015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58615916955\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##this accuracy is not good, if we do this problem with deep learning then the score will improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
